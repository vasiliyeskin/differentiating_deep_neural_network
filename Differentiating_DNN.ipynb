{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Differentiating_DNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasiliyeskin/differentiating_deep_neural_network/blob/main/Differentiating_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Zj9NzJ3LaM"
      },
      "source": [
        "# Differentiating Deep Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbiEnxax3ygf"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/vasiliyeskin/differentiating_deep_neural_network/blob/main/Differentiating_DNN.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/vasiliyeskin/differentiating_deep_neural_network/blob/main/Differentiating_DNN.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GGpvYck8rky"
      },
      "source": [
        "Used model Seq2Seq-with-attention is based on the model which is written in https://www.tensorflow.org/tutorials/text/nmt_with_attention and https://github.com/tensorflow/nmt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPRG3-hnyVXX"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import csv\n",
        "import random"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeK-BFaZm2UH"
      },
      "source": [
        "teacher_forcing_ratio = 0.75"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkx_jQPn_zp0"
      },
      "source": [
        "## The encoder and decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWY2R9LBAFem"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwar-Cp6AWT7"
      },
      "source": [
        "Implement of [Bahdanau Attention](https://arxiv.org/pdf/1409.0473.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyhQpHa4Ak0P"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(Attention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VyNGx-8AtOu"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    # forward_layer = tf.keras.layers.GRU(self.dec_units,\n",
        "    #                                return_sequences=True,\n",
        "    #                                return_state=True,\n",
        "    #                                recurrent_initializer='glorot_uniform')\n",
        "    # backward_layer = tf.keras.layers.GRU(self.dec_units,\n",
        "    #                                return_sequences=True,\n",
        "    #                                return_state=True,\n",
        "    #                                recurrent_initializer='glorot_uniform')\n",
        "    # self.gru = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer,\n",
        "    #                      input_shape=(embedding_dim, self.dec_units))\n",
        "\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = Attention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifUuqnm1Ax3P"
      },
      "source": [
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_VpNyMEBr0r",
        "outputId": "a62f86e7-5263-40f3-99e3-009c66c54cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# !wget https://github.com/vasiliyeskin/differentiating_deep_neural_network/blob/main/toy_revert/train.csv\n",
        "\n",
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNnhlFupEgd3",
        "outputId": "407c460d-b8a6-4b15-ae77-185d9a014873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import os\n",
        "# from getpass import getpass\n",
        "# import urllib\n",
        "\n",
        "# user = 'vasiliyeskin'\n",
        "# # user = input('User name: ')\n",
        "# password = getpass('Password: ')\n",
        "# password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# # repo_name = input('Repo name: ')\n",
        "# repo_name = 'differentiating_deep_neural_network'\n",
        "# destination_dir = '/content/gdrive/My Drive/{0}'.format(repo_name)\n",
        "\n",
        "# ### run first time if repo is absence\n",
        "# # cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git \\'{3}\\''.format(user, password, repo_name, destination_dir)\n",
        "\n",
        "# ### run next times\n",
        "# cmd_string = 'git -C \\'{0}\\' pull'.format(destination_dir)\n",
        "\n",
        "# print(cmd_string)\n",
        "# os.system(cmd_string)\n",
        "# cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Password: ··········\n",
            "git -C '/content/gdrive/My Drive/differentiating_deep_neural_network' pull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6a3aJMRbr9j"
      },
      "source": [
        "## Test of the model on the revert sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8BIA84ZS3Nx"
      },
      "source": [
        "repo_dir = '/content/gdrive/My Drive/differentiating_deep_neural_network'\n",
        "path_to_file = repo_dir + \"/dataset/differentiating_expressions.csv\"\n",
        "\n",
        "# path_to_file = \"dataset/differentiating_expressions.csv\" # for the home test"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgphxS1SUMcf"
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<sos> ' + w + ' <eos>'\n",
        "  return w"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bObsnB9XqmE",
        "outputId": "07433b89-b627-4b24-8902-ac94a0747002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Return word pairs in the format: [src, inverse src]\n",
        "def create_dataset(path, num_examples):\n",
        "  # lines = io.open(path).read().strip().split('\\n')\n",
        "\n",
        "  # word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  word_pairs = [[preprocess_sentence(row['variable'] + ' ' + row['expression']), preprocess_sentence(row['result'])] for row in csv.DictReader(open(path, newline=''))]\n",
        "\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "src, trg = create_dataset(path_to_file, None)\n",
        "print(src[-2])\n",
        "print(trg[-2])\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> z \\frac { 1 } {  ( \\frac { 1 } { d - z } )  + 9 } <eos>\n",
            "<sos> ( \\frac { 1 } { ( d - z ) ^ { 2 } } ) ( - \\frac { 1 } { (  ( \\frac { 1 } { d - z } )  + 9 ) ^ { 2 } } ) <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMEIyEEaZmld"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoianK2lZpam"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  src, trg = create_dataset(path, num_examples)\n",
        "\n",
        "  src_tensor, src_lang_tokenizer = tokenize(src)\n",
        "  trg_tensor, trg_lang_tokenizer = tokenize(trg)\n",
        "\n",
        "  return src_tensor, trg_tensor, src_lang_tokenizer, trg_lang_tokenizer"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0AAFhVnaZy7",
        "outputId": "71daf0f1-7d0e-4c9c-a5f2-9d263c7d9ff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "src_tensor, trg_tensor, src_lang, trg_lang = load_dataset(path_to_file)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_trg, max_length_src = trg_tensor.shape[1], src_tensor.shape[1]\n",
        "max_length_trg = 100\n",
        "max_length_src = 100\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "src_tensor_train, src_tensor_val, trg_tensor_train, trg_tensor_val = train_test_split(src_tensor, trg_tensor, test_size=0.1)\n",
        "\n",
        "# Show length\n",
        "print(len(src_tensor_train), len(trg_tensor_train), len(src_tensor_val), len(trg_tensor_val))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30096 30096 3344 3344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwJbgIaIcInH"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9hM53cOcLAl",
        "outputId": "5c1ae92f-654e-4276-a700-d593150e94f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (\"Input sequence; index to word mapping\")\n",
        "convert(src_lang, src_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target sequence; index to word mapping\")\n",
        "convert(trg_lang, trg_tensor_train[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sequence; index to word mapping\n",
            "3 ----> <sos>\n",
            "48 ----> z\n",
            "1 ----> (\n",
            "82 ----> 3\n",
            "7 ----> ^\n",
            "5 ----> {\n",
            "48 ----> z\n",
            "6 ----> }\n",
            "2 ----> )\n",
            "62 ----> \\nu\n",
            "4 ----> <eos>\n",
            "\n",
            "Target sequence; index to word mapping\n",
            "9 ----> <sos>\n",
            "1 ----> (\n",
            "81 ----> 3\n",
            "6 ----> ^\n",
            "3 ----> {\n",
            "46 ----> z\n",
            "4 ----> }\n",
            "13 ----> \\ln\n",
            "1 ----> (\n",
            "81 ----> 3\n",
            "2 ----> )\n",
            "2 ----> )\n",
            "1 ----> (\n",
            "65 ----> \\nu\n",
            "2 ----> )\n",
            "10 ----> <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHZesSc_cfGZ"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90eFiNXych1M"
      },
      "source": [
        "BUFFER_SIZE = len(src_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(src_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(src_lang.word_index) + 1\n",
        "vocab_tar_size = len(trg_lang.word_index) + 1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_tensor_train, trg_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices((src_tensor_val, trg_tensor_val))\n",
        "# dataset_val = dataset_val.batch(BATCH_SIZE)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjFTaSKtc2s1",
        "outputId": "d8495230-9df6-4f07-f0e7-b76cabe3cf6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "example_src_batch, example_trg_batch = next(iter(dataset))\n",
        "example_src_batch.shape, example_trg_batch.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 22]), TensorShape([64, 49]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGV5ukqmdHPK"
      },
      "source": [
        "### Get encode and decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2s48uZedMx7",
        "outputId": "a3071cb2-7541-4f4d-9e0e-d534f4ef140d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_src_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 22, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP_xxQYPecx8",
        "outputId": "6576b15c-fc0d-4f93-fd51-3b656f23c152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "attention_layer = Attention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 22, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8w8UDMkeqc4",
        "outputId": "f516fd6a-b3f6-4575-d57e-9b6e01cef796",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQBtocxze6K4"
      },
      "source": [
        "### Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxssNvIiety3"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k1nocs6fGdv"
      },
      "source": [
        "### Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c6rqGc3fI-0"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMkTwfxCfZ4E"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfTMVPbBfc_D"
      },
      "source": [
        "@tf.function\n",
        "def train_step(src, trg, enc_hidden, teacher_forcing_ratio = 0.5):\n",
        "  loss = 0\n",
        "\n",
        "  #decide if we are going to use teacher forcing or not\n",
        "  teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    enc_output, enc_hidden = encoder(src, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_src = tf.expand_dims([trg_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next src\n",
        "    for t in range(1, trg.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_src, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(trg[:, t], predictions)\n",
        "\n",
        "\n",
        "      #if teacher forcing, use actual next token as next input\n",
        "      #if not, use predicted token\n",
        "      if teacher_force:\n",
        "        dec_src = tf.expand_dims(trg[:, t], 1)\n",
        "      else:\n",
        "        pred = tf.argmax(predictions,1)\n",
        "        dec_src = tf.expand_dims(pred,1)\n",
        "\n",
        "\n",
        "  batch_loss = (loss / int(trg.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3pXQDBUvjrt"
      },
      "source": [
        "def validation_step(src, trg, enc_hidden):\n",
        "  loss = 0\n",
        "  \n",
        "  print(src.shape)\n",
        "  print(enc_hidden.shape)\n",
        "\n",
        "  enc_output, enc_hidden = encoder(src, enc_hidden)\n",
        "  \n",
        "  dec_hidden = enc_hidden\n",
        "\n",
        "  dec_src = tf.expand_dims([trg_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  for t in range(1, trg.shape[1]):\n",
        "    # passing enc_output to the decoder\n",
        "    predictions, dec_hidden, _ = decoder(dec_src, dec_hidden, enc_output)\n",
        "\n",
        "    loss += loss_function(trg[:, t], predictions)\n",
        "    \n",
        "    preds = tf.argmax(predictions,1)\n",
        "    dec_src = tf.expand_dims(preds, 1)\n",
        "    \n",
        "    # print(dec_src)\n",
        "    # if  dec_src == trg_lang.word_index['<sos>']:\n",
        "    #   break\n",
        "\n",
        "  batch_loss = (loss / int(trg.shape[1]))\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3msflmffxk2",
        "outputId": "3b6ba2ca-52ea-42a0-bd1e-5a41393d26ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "min_loss = 100\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (src, trg)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(src, trg, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "      \n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if min_loss > total_loss:\n",
        "    min_loss = total_loss\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "\n",
        "  # # enc_hidden = encoder.initialize_hidden_state()\n",
        "  # total_val_loss = 0\n",
        "  # for (batch, (src, trg)) in enumerate(dataset_val.take(steps_per_epoch)):\n",
        "  #   val_loss = validation_step(src, trg, enc_hidden)\n",
        "  #   total_val_loss += val_loss\n",
        "  # print('Epoch {} Validation Loss {:.4f}'.format(epoch + 1, val_loss))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.2687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-977ee06b83d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sko_cujukvpa"
      },
      "source": [
        "### Differentiating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4THH7bE6lMjY"
      },
      "source": [
        "def evaluate_of_tensor(input_tensors, attention_plot):\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(input_tensors, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([trg_lang.word_index['<sos>']], 0)\n",
        "\n",
        "  for t in range(max_length_trg):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += trg_lang.index_word[predicted_id]\n",
        "\n",
        "    if trg_lang.index_word[predicted_id] == '<eos>':\n",
        "      return result, attention_plot\n",
        "\n",
        "    result += ' '\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qJFUS98kz2Y"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_trg, max_length_src))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [src_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_src,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  # result = ''\n",
        "\n",
        "  # hidden = [tf.zeros((1, units))]\n",
        "  # enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  # dec_hidden = enc_hidden\n",
        "  # dec_input = tf.expand_dims([trg_lang.word_index['<sos>']], 0)\n",
        "\n",
        "  # for t in range(max_length_trg):\n",
        "  #   predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "  #                                                        dec_hidden,\n",
        "  #                                                        enc_out)\n",
        "\n",
        "  #   # storing the attention weights to plot later on\n",
        "  #   attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "  #   attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "  #   predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "  #   result += trg_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "  #   if trg_lang.index_word[predicted_id] == '<eos>':\n",
        "  #     return result, sentence, attention_plot\n",
        "\n",
        "  #   # the predicted ID is fed back into the model\n",
        "  #   dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  # return result, sentence, attention_plot\n",
        "  result, attention_plot = evaluate_of_tensor(inputs, attention_plot)\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwROPNezlJ1v"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMiGkiiklg5E"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTmNo3silo4p"
      },
      "source": [
        "### Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dqun3kdlqnp",
        "outputId": "5f3df43b-435d-42d7-e89a-d3e842b173f0"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f5455397128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6gIRRJLlxOO",
        "outputId": "d59765f0-53c8-4335-998c-3e1266ede748"
      },
      "source": [
        "translate('b a ^ b')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <sos> b a ^ b <eos>\n",
            "Predicted translation: { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrjFiTVunbVm"
      },
      "source": [
        "translate('a b c c c c c')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjyAz1l9Yldj"
      },
      "source": [
        "# # install torchtext with BLUE module\n",
        "# !pip3 install torchtext==0.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0NKpT4w0Dbu"
      },
      "source": [
        "def tensor_to_sequence(input):\n",
        "  result = ''\n",
        "  for id in range(1, input.shape[0]):\n",
        "    in_id = input[id].numpy()\n",
        "    result += trg_lang.index_word[in_id]\n",
        "\n",
        "    if trg_lang.index_word[in_id] == '<eos>':\n",
        "      return result\n",
        "\n",
        "    result += ' '\n",
        "\n",
        "  return result[:-1]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHpVLOQ2GoZe"
      },
      "source": [
        "# from torchtext.data.metrics import bleu_score\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def calculate_bleu(data):\n",
        "    \n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    \n",
        "    attention_plot = np.zeros((max_length_trg, max_length_src))\n",
        "\n",
        "    I = 0\n",
        "    \n",
        "    for _, (src, trg) in enumerate(data.shuffle(BATCH_SIZE)):\n",
        "        \n",
        "        # src = vars(datum)['src']\n",
        "        # trg = vars(datum)['trg']\n",
        "        \n",
        "        # pred_trg, _ = translate(src)\n",
        "        # print(tf.reshape(src[1:],[1, src.shape[0]-1]))\n",
        "\n",
        "        #cut off <eos> token\n",
        "        src_tensor = tf.reshape(src,[1, src.shape[0]])\n",
        "        #cut off <eos> token\n",
        "        # src_tensor = src_tensor[:-2]\n",
        "        # print(src_tensor)\n",
        "        pred_trg, _ = evaluate_of_tensor(src_tensor, attention_plot)\n",
        "        # print(pred_trg)\n",
        "\n",
        "        #cut off <eos> token\n",
        "        # pred_trg = pred_trg[:-1]\n",
        "        \n",
        "        pred_trgs.append(pred_trg)\n",
        "        trg_seq = tensor_to_sequence(trg)\n",
        "        trgs.append(trg_seq)\n",
        "        # print('Pred: {0}'.format(pred_trg))\n",
        "        # print('Trg:  {0}'.format(trg_seq))\n",
        "        bleu_score = sentence_bleu([pred_trg.split(' ')], trg_seq.split(' '))\n",
        "        print(f'BLEU score = {bleu_score*100:.2f}')\n",
        "        I += 1\n",
        "        if I > 100:\n",
        "          break\n",
        "\n",
        "    # print([pred_trgs])\n",
        "    # print(trgs)\n",
        "    # return bleu_score(pred_trgs, trgs)\n",
        "    return sentence_bleu(pred_trgs, trgs)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lie3WBWYFNI"
      },
      "source": [
        "bleu_score = calculate_bleu(dataset_val)\n",
        "\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTXEkYbWr2Xp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYkxi9mu4e6-"
      },
      "source": [
        "### Draw the expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwB6zCfk5Enx"
      },
      "source": [
        "#### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnAy2oAj5zv4",
        "outputId": "26bf62ec-2b09-4bf4-88c7-96ba753f2a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/differentiating_deep_neural_network"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/differentiating_deep_neural_network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPUL1L7E6ehK"
      },
      "source": [
        "import csv\n",
        "import random\n",
        "import sys, os, re, shutil, argparse, logging\n",
        "from multiprocessing import Pool\n",
        "from multiprocessing.dummy import Pool as ThreadPool\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import subprocess, shlex\n",
        "from threading import Timer\n",
        "\n",
        "\n",
        "TIMEOUT = 30\n",
        "\n",
        "# replace \\pmatrix with \\begin{pmatrix}\\end{pmatrix}\n",
        "# replace \\matrix with \\begin{matrix}\\end{matrix}\n",
        "template = r\"\"\"\n",
        "\\documentclass[12pt]{article}\n",
        "\\pagestyle{empty}\n",
        "\\usepackage{amsmath}\n",
        "\\newcommand{\\mymatrix}[1]{\\begin{matrix}#1\\end{matrix}}\n",
        "\\newcommand{\\mypmatrix}[1]{\\begin{pmatrix}#1\\end{pmatrix}}\n",
        "\\begin{document}\n",
        "\\begin{displaymath}\n",
        "%s\n",
        "\\end{displaymath}\n",
        "\\end{document}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def latex2png(line):\n",
        "    img_path, l, output_path, replace = line\n",
        "    pre_name = output_path.replace('/', '_').replace('.','_')\n",
        "    l = l.strip()\n",
        "    l = l.replace(r'\\pmatrix', r'\\mypmatrix')\n",
        "    l = l.replace(r'\\matrix', r'\\mymatrix')\n",
        "    # remove leading comments\n",
        "    l = l.strip('%')\n",
        "    if len(l) == 0:\n",
        "        l = '\\\\hspace{1cm}'\n",
        "    # \\hspace {1 . 5 cm} -> \\hspace {1.5cm}\n",
        "    for space in [\"hspace\", \"vspace\"]:\n",
        "        match = re.finditer(space + \" {(.*?)}\", l)\n",
        "        if match:\n",
        "            new_l = \"\"\n",
        "            last = 0\n",
        "            for m in match:\n",
        "                new_l = new_l + l[last:m.start(1)] + m.group(1).replace(\" \", \"\")\n",
        "                last = m.end(1)\n",
        "            new_l = new_l + l[last:]\n",
        "            l = new_l\n",
        "    if replace or (not os.path.exists(output_path)):\n",
        "        tex_filename = pre_name+'.tex'\n",
        "        log_filename = pre_name+'.log'\n",
        "        aux_filename = pre_name+'.aux'\n",
        "        with open(tex_filename, \"w\") as outputfile:\n",
        "            outputfile.write(template%l)\n",
        "        run(\"pdflatex -interaction=nonstopmode %s  >/dev/null\" % tex_filename, TIMEOUT)\n",
        "        os.remove(tex_filename)\n",
        "        os.remove(log_filename)\n",
        "        os.remove(aux_filename)\n",
        "        pdf_filename = tex_filename[:-4]+'.pdf'\n",
        "        png_filename = tex_filename[:-4]+'.png'\n",
        "        if not os.path.exists(pdf_filename):\n",
        "            print('cannot compile')\n",
        "        else:\n",
        "            os.system(\"convert -density 200 -quality 100 %s %s\"%(pdf_filename, png_filename))\n",
        "            os.remove(pdf_filename)\n",
        "            if os.path.exists(png_filename):\n",
        "                crop_image(png_filename, output_path)\n",
        "                os.remove(png_filename)\n",
        "\n",
        "\n",
        "\n",
        "def crop_image(img, output_path, default_size=None):\n",
        "    old_im = Image.open(img).convert('L')\n",
        "    img_data = np.asarray(old_im, dtype=np.uint8) # height, width\n",
        "    nnz_inds = np.where(img_data!=255)\n",
        "    if len(nnz_inds[0]) == 0:\n",
        "        if not default_size:\n",
        "            old_im.save(output_path)\n",
        "            return False\n",
        "        else:\n",
        "            assert len(default_size) == 2, default_size\n",
        "            x_min,y_min,x_max,y_max = 0,0,default_size[0],default_size[1]\n",
        "            old_im = old_im.crop((x_min, y_min, x_max+1, y_max+1))\n",
        "            old_im.save(output_path)\n",
        "            return False\n",
        "    y_min = np.min(nnz_inds[0])\n",
        "    y_max = np.max(nnz_inds[0])\n",
        "    x_min = np.min(nnz_inds[1])\n",
        "    x_max = np.max(nnz_inds[1])\n",
        "    old_im = old_im.crop((x_min, y_min, x_max+1, y_max+1))\n",
        "    old_im.save(output_path)\n",
        "    return True\n",
        "\n",
        "def run(cmd, timeout_sec):\n",
        "    proc = subprocess.Popen(cmd, shell=True)\n",
        "    kill_proc = lambda p: p.kill()\n",
        "    timer = Timer(timeout_sec, kill_proc, [proc])\n",
        "    try:\n",
        "        timer.start()\n",
        "        stdout,stderr = proc.communicate()\n",
        "    finally:\n",
        "        timer.cancel()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW5qvZGv5WjP"
      },
      "source": [
        "#### Drawing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8qfULPY66QE"
      },
      "source": [
        "# install texlive\n",
        "! sudo apt-get install texlive-latex-recommended"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QzgXAHo_2vNX",
        "outputId": "e9cbe83d-97a6-4d42-b310-2f2ccae71df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "# import utils.utils as util\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "I = 0\n",
        "for _, (src, trg) in enumerate(dataset_val):\n",
        "    trg_seq = tensor_to_sequence(trg)\n",
        "    trg_seq = trg_seq[:-5]\n",
        "    rander_output = 'test_rendering/formula{0}.png'\n",
        "\n",
        "    line = 'test_rendering/test_rendering.png', trg_seq, rander_output.format(I), True\n",
        "    # util.latex2png(line)\n",
        "    latex2png(line)\n",
        "    print(trg_seq)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    # plt.imshow(img)\n",
        "    imgplot = plt.imshow( mpimg.imread(rander_output.format(I)))\n",
        "    plt.show()\n",
        "    \n",
        "    I += 1\n",
        "    if I > 10:\n",
        "        break"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "( \\frac { 1 } { ( \\psi - i ) ^ { 2 } } ) ( \\frac { 1 } { \\sqrt { 1 - ( \\frac { 1 } { \\psi - i } ) ^ { 2 } } } ) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-2926f94f1cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# plt.imshow(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mimgplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrander_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_rendering/formula0.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytx5TXN95iZR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}