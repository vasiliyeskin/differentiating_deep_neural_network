{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Differentiating_DNN.ipynb",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "pycharm-a661a43c",
   "language": "python",
   "display_name": "PyCharm (differentiating_deep_neural_network)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vasiliyeskin/differentiating_deep_neural_network/blob/main/Differentiating_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5Zj9NzJ3LaM"
   },
   "source": [
    "# Differentiating Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbiEnxax3ygf"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/vasiliyeskin/differentiating_deep_neural_network/blob/main/Differentiating_DNN.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/vasiliyeskin/differentiating_deep_neural_network/blob/main/Differentiating_DNN.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GGpvYck8rky"
   },
   "source": [
    "Used model Seq2Seq-with-attention is based on the model which is written in https://www.tensorflow.org/tutorials/text/nmt_with_attention and https://github.com/tensorflow/nmt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JPRG3-hnyVXX"
   },
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import csv\n",
    "import random"
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qeK-BFaZm2UH"
   },
   "source": [
    "teacher_forcing_ratio = 0.75"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hkx_jQPn_zp0"
   },
   "source": [
    "## The encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZWY2R9LBAFem"
   },
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))\n"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gwar-Cp6AWT7"
   },
   "source": [
    "Implement of [Bahdanau Attention](https://arxiv.org/pdf/1409.0473.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eyhQpHa4Ak0P"
   },
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(Attention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5VyNGx-8AtOu"
   },
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    # forward_layer = tf.keras.layers.GRU(self.dec_units,\n",
    "    #                                return_sequences=True,\n",
    "    #                                return_state=True,\n",
    "    #                                recurrent_initializer='glorot_uniform')\n",
    "    # backward_layer = tf.keras.layers.GRU(self.dec_units,\n",
    "    #                                return_sequences=True,\n",
    "    #                                return_state=True,\n",
    "    #                                recurrent_initializer='glorot_uniform')\n",
    "    # self.gru = tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer,\n",
    "    #                      input_shape=(embedding_dim, self.dec_units))\n",
    "\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = Attention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ],
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifUuqnm1Ax3P"
   },
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B_VpNyMEBr0r",
    "outputId": "5095c0f2-76a9-427d-dda7-2f5ea98e8af6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# !wget https://github.com/vasiliyeskin/differentiating_deep_neural_network/blob/main/toy_revert/train.csv\n",
    "\n",
    "#connect to google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TNnhlFupEgd3"
   },
   "source": [
    "# import os\n",
    "# from getpass import getpass\n",
    "# import urllib\n",
    "\n",
    "# user = 'vasiliyeskin'\n",
    "# # user = input('User name: ')\n",
    "# password = getpass('Password: ')\n",
    "# password = urllib.parse.quote(password) # your password is converted into url format\n",
    "# # repo_name = input('Repo name: ')\n",
    "# repo_name = 'differentiating_deep_neural_network'\n",
    "# destination_dir = '/content/gdrive/My Drive/{0}'.format(repo_name)\n",
    "\n",
    "# ### run first time if repo is absence\n",
    "# # cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git \\'{3}\\''.format(user, password, repo_name, destination_dir)\n",
    "\n",
    "# ### run next times\n",
    "# cmd_string = 'git -C \\'{0}\\' pull'.format(destination_dir)\n",
    "\n",
    "# print(cmd_string)\n",
    "# os.system(cmd_string)\n",
    "# cmd_string, password = \"\", \"\" # removing the password from the variable"
   ],
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6a3aJMRbr9j"
   },
   "source": [
    "## Test of the model on the revert sequence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E8BIA84ZS3Nx"
   },
   "source": [
    "repo_dir = '/content/gdrive/My Drive/differentiating_deep_neural_network'\n",
    "path_to_file = repo_dir + \"/dataset/differentiating_expressions.csv\"\n",
    "\n",
    "# path_to_file = \"dataset/differentiating_expressions.csv\" # for the home test"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YgphxS1SUMcf"
   },
   "source": [
    "def preprocess_sentence(w):\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<sos> ' + w + ' <eos>'\n",
    "  return w"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7bObsnB9XqmE",
    "outputId": "722bf8d2-2bd3-4bce-ce74-87593a0f7d15",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Return word pairs in the format: [src, inverse src]\n",
    "def create_dataset(path, num_examples):\n",
    "  # lines = io.open(path).read().strip().split('\\n')\n",
    "\n",
    "  # word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "  word_pairs = [[preprocess_sentence(row['variable'] + ' ' + row['expression']), preprocess_sentence(row['result'])] for row in csv.DictReader(open(path, newline=''))]\n",
    "\n",
    "  return zip(*word_pairs)\n",
    "\n",
    "src, trg = create_dataset(path_to_file, None)\n",
    "print(src[-2])\n",
    "print(trg[-2])\n"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> z \\frac { 1 } {  ( \\frac { 1 } { d - z } )  + 9 } <eos>\n",
      "<sos> ( \\frac { 1 } { ( d - z ) ^ { 2 } } ) ( - \\frac { 1 } { (  ( \\frac { 1 } { d - z } )  + 9 ) ^ { 2 } } ) <eos>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lMEIyEEaZmld"
   },
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IoianK2lZpam"
   },
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  src, trg = create_dataset(path, num_examples)\n",
    "\n",
    "  src_tensor, src_lang_tokenizer = tokenize(src)\n",
    "  trg_tensor, trg_lang_tokenizer = tokenize(trg)\n",
    "\n",
    "  return src_tensor, trg_tensor, src_lang_tokenizer, trg_lang_tokenizer"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H0AAFhVnaZy7",
    "outputId": "b47eccc6-83d4-4d06-e942-c2fb398742ab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "src_tensor, trg_tensor, src_lang, trg_lang = load_dataset(path_to_file)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_trg, max_length_src = trg_tensor.shape[1], src_tensor.shape[1]\n",
    "max_length_trg = 100\n",
    "max_length_src = 100\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "src_tensor_train, src_tensor_val, trg_tensor_train, trg_tensor_val = train_test_split(src_tensor, trg_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "print(len(src_tensor_train), len(trg_tensor_train), len(src_tensor_val), len(trg_tensor_val))\n"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30096 30096 3344 3344\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qwJbgIaIcInH"
   },
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d9hM53cOcLAl",
    "outputId": "0e26ad6a-a602-413d-dd9d-b148bc1db144",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print (\"Input sequence; index to word mapping\")\n",
    "convert(src_lang, src_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target sequence; index to word mapping\")\n",
    "convert(trg_lang, trg_tensor_train[0])"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence; index to word mapping\n",
      "3 ----> <sos>\n",
      "63 ----> \\alpha\n",
      "48 ----> z\n",
      "7 ----> ^\n",
      "5 ----> {\n",
      "1 ----> (\n",
      "81 ----> 2\n",
      "7 ----> ^\n",
      "5 ----> {\n",
      "63 ----> \\alpha\n",
      "6 ----> }\n",
      "2 ----> )\n",
      "6 ----> }\n",
      "4 ----> <eos>\n",
      "\n",
      "Target sequence; index to word mapping\n",
      "9 ----> <sos>\n",
      "1 ----> (\n",
      "11 ----> 2\n",
      "6 ----> ^\n",
      "3 ----> {\n",
      "63 ----> \\alpha\n",
      "4 ----> }\n",
      "13 ----> \\ln\n",
      "1 ----> (\n",
      "11 ----> 2\n",
      "2 ----> )\n",
      "2 ----> )\n",
      "1 ----> (\n",
      "46 ----> z\n",
      "6 ----> ^\n",
      "3 ----> {\n",
      "1 ----> (\n",
      "11 ----> 2\n",
      "6 ----> ^\n",
      "3 ----> {\n",
      "63 ----> \\alpha\n",
      "4 ----> }\n",
      "2 ----> )\n",
      "4 ----> }\n",
      "13 ----> \\ln\n",
      "1 ----> (\n",
      "46 ----> z\n",
      "2 ----> )\n",
      "2 ----> )\n",
      "10 ----> <eos>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHZesSc_cfGZ"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "90eFiNXych1M"
   },
   "source": [
    "BUFFER_SIZE = len(src_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(src_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(src_lang.word_index) + 1\n",
    "vocab_tar_size = len(trg_lang.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_tensor_train, trg_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((src_tensor_val, trg_tensor_val))\n",
    "# dataset_val = dataset_val.batch(BATCH_SIZE)\n"
   ],
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gjFTaSKtc2s1",
    "outputId": "87d464e5-0ac1-43b6-b63e-838cda4a4981",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "example_src_batch, example_trg_batch = next(iter(dataset))\n",
    "example_src_batch.shape, example_trg_batch.shape"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorShape([64, 22]), TensorShape([64, 49]))"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGV5ukqmdHPK"
   },
   "source": [
    "### Get encode and decode"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l2s48uZedMx7",
    "outputId": "012bd18f-e648-49ea-e3cd-d09c86f7a188",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_src_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 22, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fP_xxQYPecx8",
    "outputId": "5a8286c0-089f-44b3-ee0b-dfdaa88ed10a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "attention_layer = Attention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 22, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C8w8UDMkeqc4",
    "outputId": "81b75727-c8bd-4e5a-a057-b7d7b8127bd8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 85)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQBtocxze6K4"
   },
   "source": [
    "### Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pxssNvIiety3"
   },
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n"
   ],
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k1nocs6fGdv"
   },
   "source": [
    "### Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9c6rqGc3fI-0"
   },
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMkTwfxCfZ4E"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bfTMVPbBfc_D"
   },
   "source": [
    "@tf.function\n",
    "def train_step(src, trg, enc_hidden, teacher_forcing_ratio = 0.5):\n",
    "  loss = 0\n",
    "\n",
    "  #decide if we are going to use teacher forcing or not\n",
    "  teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    enc_output, enc_hidden = encoder(src, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_src = tf.expand_dims([trg_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next src\n",
    "    for t in range(1, trg.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_src, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(trg[:, t], predictions)\n",
    "\n",
    "\n",
    "      #if teacher forcing, use actual next token as next input\n",
    "      #if not, use predicted token\n",
    "      if teacher_force:\n",
    "        dec_src = tf.expand_dims(trg[:, t], 1)\n",
    "      else:\n",
    "        pred = tf.argmax(predictions,1)\n",
    "        dec_src = tf.expand_dims(pred,1)\n",
    "\n",
    "\n",
    "  batch_loss = (loss / int(trg.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O3pXQDBUvjrt"
   },
   "source": [
    "def validation_step(src, trg, enc_hidden):\n",
    "  loss = 0\n",
    "  \n",
    "  print(src.shape)\n",
    "  print(enc_hidden.shape)\n",
    "\n",
    "  enc_output, enc_hidden = encoder(src, enc_hidden)\n",
    "  \n",
    "  dec_hidden = enc_hidden\n",
    "\n",
    "  dec_src = tf.expand_dims([trg_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
    "\n",
    "  for t in range(1, trg.shape[1]):\n",
    "    # passing enc_output to the decoder\n",
    "    predictions, dec_hidden, _ = decoder(dec_src, dec_hidden, enc_output)\n",
    "\n",
    "    loss += loss_function(trg[:, t], predictions)\n",
    "    \n",
    "    preds = tf.argmax(predictions,1)\n",
    "    dec_src = tf.expand_dims(preds, 1)\n",
    "    \n",
    "    # print(dec_src)\n",
    "    # if  dec_src == trg_lang.word_index['<sos>']:\n",
    "    #   break\n",
    "\n",
    "  batch_loss = (loss / int(trg.shape[1]))\n",
    "  return batch_loss"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X3msflmffxk2",
    "outputId": "3b6ba2ca-52ea-42a0-bd1e-5a41393d26ae",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    }
   },
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "min_loss = 100\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (src, trg)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(src, trg, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "      \n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if min_loss > total_loss:\n",
    "    min_loss = total_loss\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "\n",
    "  # # enc_hidden = encoder.initialize_hidden_state()\n",
    "  # total_val_loss = 0\n",
    "  # for (batch, (src, trg)) in enumerate(dataset_val.take(steps_per_epoch)):\n",
    "  #   val_loss = validation_step(src, trg, enc_hidden)\n",
    "  #   total_val_loss += val_loss\n",
    "  # print('Epoch {} Validation Loss {:.4f}'.format(epoch + 1, val_loss))\n"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.2687\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-63-977ee06b83d7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m   \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0mbatch_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menc_hidden\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     \u001B[0mtotal_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mbatch_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    778\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    805\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    806\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 807\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    808\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    809\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2828\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2829\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2830\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2831\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[0;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1846\u001B[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001B[1;32m   1847\u001B[0m         \u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1848\u001B[0;31m         cancellation_manager=cancellation_manager)\n\u001B[0m\u001B[1;32m   1849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1850\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_flat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcancellation_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1922\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1923\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1924\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1925\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1926\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    548\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    551\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sko_cujukvpa"
   },
   "source": [
    "### Differentiating"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4THH7bE6lMjY"
   },
   "source": [
    "def evaluate_of_tensor(input_tensors, attention_plot):\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(input_tensors, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([trg_lang.word_index['<sos>']], 0)\n",
    "\n",
    "  for t in range(max_length_trg):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += trg_lang.index_word[predicted_id]\n",
    "\n",
    "    if trg_lang.index_word[predicted_id] == '<eos>':\n",
    "      return result, attention_plot\n",
    "\n",
    "    result += ' '\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, attention_plot"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5qJFUS98kz2Y"
   },
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_trg, max_length_src))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [src_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_src,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  # result = ''\n",
    "\n",
    "  # hidden = [tf.zeros((1, units))]\n",
    "  # enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  # dec_hidden = enc_hidden\n",
    "  # dec_input = tf.expand_dims([trg_lang.word_index['<sos>']], 0)\n",
    "\n",
    "  # for t in range(max_length_trg):\n",
    "  #   predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "  #                                                        dec_hidden,\n",
    "  #                                                        enc_out)\n",
    "\n",
    "  #   # storing the attention weights to plot later on\n",
    "  #   attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "  #   attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "  #   predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "  #   result += trg_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "  #   if trg_lang.index_word[predicted_id] == '<eos>':\n",
    "  #     return result, sentence, attention_plot\n",
    "\n",
    "  #   # the predicted ID is fed back into the model\n",
    "  #   dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  # return result, sentence, attention_plot\n",
    "  result, attention_plot = evaluate_of_tensor(inputs, attention_plot)\n",
    "  return result, sentence, attention_plot"
   ],
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cwROPNezlJ1v"
   },
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()\n"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mMiGkiiklg5E"
   },
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n"
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTmNo3silo4p"
   },
   "source": [
    "### Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_dqun3kdlqnp"
   },
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ],
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f5455397128>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y6gIRRJLlxOO"
   },
   "source": [
    "translate('b a ^ b')"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <sos> b a ^ b <eos>\n",
      "Predicted translation: { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { { \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SrjFiTVunbVm"
   },
   "source": [
    "translate('a b c c c c c')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rjyAz1l9Yldj"
   },
   "source": [
    "# # install torchtext with BLUE module\n",
    "# !pip3 install torchtext==0.8.0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t0NKpT4w0Dbu"
   },
   "source": [
    "def tensor_to_sequence(input):\n",
    "  result = ''\n",
    "  for id in range(1, input.shape[0]):\n",
    "    in_id = input[id].numpy()\n",
    "    result += trg_lang.index_word[in_id]\n",
    "\n",
    "    if trg_lang.index_word[in_id] == '<eos>':\n",
    "      return result\n",
    "\n",
    "    result += ' '\n",
    "\n",
    "  return result[:-1]"
   ],
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BHpVLOQ2GoZe"
   },
   "source": [
    "# from torchtext.data.metrics import bleu_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calculate_bleu(data):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    attention_plot = np.zeros((max_length_trg, max_length_src))\n",
    "\n",
    "    I = 0\n",
    "    \n",
    "    for _, (src, trg) in enumerate(data.shuffle(BATCH_SIZE)):\n",
    "        \n",
    "        # src = vars(datum)['src']\n",
    "        # trg = vars(datum)['trg']\n",
    "        \n",
    "        # pred_trg, _ = translate(src)\n",
    "        # print(tf.reshape(src[1:],[1, src.shape[0]-1]))\n",
    "\n",
    "        #cut off <eos> token\n",
    "        src_tensor = tf.reshape(src,[1, src.shape[0]])\n",
    "        #cut off <eos> token\n",
    "        # src_tensor = src_tensor[:-2]\n",
    "        # print(src_tensor)\n",
    "        pred_trg, _ = evaluate_of_tensor(src_tensor, attention_plot)\n",
    "        # print(pred_trg)\n",
    "\n",
    "        #cut off <eos> token\n",
    "        # pred_trg = pred_trg[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trg_seq = tensor_to_sequence(trg)\n",
    "        trgs.append(trg_seq)\n",
    "        # print('Pred: {0}'.format(pred_trg))\n",
    "        # print('Trg:  {0}'.format(trg_seq))\n",
    "        bleu_score = sentence_bleu([pred_trg.split(' ')], trg_seq.split(' '))\n",
    "        print(f'BLEU score = {bleu_score*100:.2f}')\n",
    "        I += 1\n",
    "        if I > 100:\n",
    "          break\n",
    "\n",
    "    # print([pred_trgs])\n",
    "    # print(trgs)\n",
    "    # return bleu_score(pred_trgs, trgs)\n",
    "    return sentence_bleu(pred_trgs, trgs)"
   ],
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8Lie3WBWYFNI"
   },
   "source": [
    "bleu_score = calculate_bleu(dataset_val)\n",
    "\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ],
   "execution_count": 75,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (22) into shape (100)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-75-be1c17175b0a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mbleu_score\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalculate_bleu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'BLEU score = {bleu_score*100:.2f}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-72-6136311a220f>\u001B[0m in \u001B[0;36mcalculate_bleu\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0;31m# src_tensor = src_tensor[:-2]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;31m# print(src_tensor)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mpred_trg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate_of_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc_tensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattention_plot\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m         \u001B[0;31m# print(pred_trg)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-65-db674a454376>\u001B[0m in \u001B[0;36mevaluate_of_tensor\u001B[0;34m(input_tensors, attention_plot)\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0;31m# storing the attention weights to plot later on\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0mattention_weights\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mattention_weights\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m     \u001B[0mattention_plot\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mattention_weights\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0mpredicted_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not broadcast input array from shape (22) into shape (100)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HTXEkYbWr2Xp"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( \\frac { 1 } { u } ) ( e ^ { ( \\ln ( u ) ) } ) \n",
      "( s ^ { t } \\ln ( s ) ) ( \\frac { 1 } { ( j - ( s ^ { t } ) ) ^ { 2 } } ) \n",
      "( \\frac { 1 } { 1 + a ^ { 2 } } ) ( - \\sin ( ( \\arctan ( a ) ) ) ) \n",
      "( \\exp ( \\xi ) ) ( - \\sin ( ( \\exp ( \\xi ) ) ) ) \n",
      "( \\frac { 1 } { ( \\nu - \\varphi ) ^ { 2 } } ) ( \\frac { 1 } { \\cos ^ { 2 } ( ( \\frac { 1 } { \\nu - \\varphi } ) ) } ) \n",
      "( \\frac { 1 } { \\cos ^ { 2 } ( w ) } ) ( \\frac { 1 } { ( \\tan ( w ) ) } ) \n",
      "( - \\frac { 1 } { ( h + d ) ^ { 2 } } ) ( - \\frac { 1 } { ( ( \\frac { 1 } { h + d } ) + \\zeta ) ^ { 2 } } ) \n",
      "( 0 ) ( 1 ) \n",
      "( \\frac { 1 } { 1 + \\omega ^ { 2 } } ) ( \\frac { 1 } { \\sqrt { 1 - ( \\arctan ( \\omega ) ) ^ { 2 } } } ) \n",
      "( - \\frac { 1 } { \\sin ^ { 2 } ( \\eta ) } ) ( - \\frac { 1 } { \\sin ^ { 2 } ( ( \\cot ( \\eta ) ) ) } ) \n",
      "( - \\frac { 1 } { ( k + 7 ) ^ { 2 } } ) ( \\frac { 1 } { \\sqrt { 1 - ( \\frac { 1 } { k + 7 } ) ^ { 2 } } } ) \n"
     ]
    }
   ],
   "source": [
    "import utils.utils as utils\n",
    "\n",
    "I = 0\n",
    "for _, (src, trg) in enumerate(dataset_val):\n",
    "    trg_seq = tensor_to_sequence(trg)\n",
    "    trg_seq = trg_seq[:-5]\n",
    "    line = 'test_rendering/test_rendering.png', trg_seq, 'test_rendering/test.png', True\n",
    "    utils.latex2png(line)\n",
    "    print(trg_seq)\n",
    "    I += 1\n",
    "    if I > 10:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}